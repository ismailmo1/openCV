{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contour detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work laptop\n",
    "# imgPath = r\"C:\\Users\\ismail.mohammed\\TempScripts\\manualOEE_OMR\\OEE_forms\\v1.6_TEMPLATE.jpg\"\n",
    "\n",
    "##home laptop\n",
    "imgPath = r\"C:\\Users\\Halima Mohmed\\Documents\\OEE_OMR\\configFiles\\blankForms\\v2.1_blank0.jpg\"\n",
    "\n",
    "img = cv2.imread(imgPath)\n",
    "\n",
    "# apply rotations, resizing etc\n",
    "imgResize = cv2.resize(img, dsize=(int(img.shape[1]*0.4), int(img.shape[0]*0.4)), interpolation= cv2.INTER_AREA)\n",
    "imgGray = cv2.cvtColor(imgResize, cv2.COLOR_BGR2GRAY)\n",
    "imgBlank = np.full_like(imgResize, 255)\n",
    "\n",
    "ret, thresh = cv2.threshold(imgGray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "# find all contours based off threshold image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding corner circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[843, 650, 30], [843, 26, 30], [28, 654, 28], [28, 26, 28]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles=[]\n",
    "for c in contours:\n",
    "    (x, y), rad = (cv2.minEnclosingCircle(c))\n",
    "    circles.append([x,y,rad])\n",
    "\n",
    "#sort by radius, and then x coord - top 8 are corners (inner/outer circles)\n",
    "sorted(sorted(circles, key = lambda x:x[2], reverse=True)[0:8], key = lambda x:x[2])\n",
    "\n",
    "corners = sorted(circles, key = lambda x:x[2], reverse=True)[0:4]\n",
    "\n",
    "corners = [[round(c) for c in corner] for corner in corners]\n",
    "\n",
    "corners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## draw corners (just for visualisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corner in corners:\n",
    "    cv2.circle(imgResize, tuple(corner[0:2]), 1, (0,0,255), 20)\n",
    "\n",
    "cv2.imshow(\"corners\", imgResize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use enclosing rectangle instead of omr circles for perspective transform?\n",
    "### i.e. redesign omr sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contour detection to find corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "##work laptop\n",
    "# imgPath = r\"C:\\Users\\ismail.mohammed\\TempScripts\\manualOEE_OMR\\OEE_forms\\v1.6_TEMPLATE.jpg\"\n",
    "\n",
    "##home laptop\n",
    "imgPath = r\"C:\\Users\\Halima Mohmed\\Documents\\OEE_OMR\\configFiles\\blankForms\\v3.4_blank0.jpg\"\n",
    "\n",
    "img = cv2.imread(imgPath)\n",
    "\n",
    "# apply rotations, resizing etc\n",
    "imgResize1 = cv2.resize(img, dsize=(int(img.shape[1]*0.4), int(img.shape[0]*0.4)), interpolation= cv2.INTER_AREA)\n",
    "imgGray1 = cv2.cvtColor(imgResize1, cv2.COLOR_BGR2GRAY)\n",
    "imgBlank1 = np.full_like(imgResize1, 255)\n",
    "\n",
    "ret, thresh = cv2.threshold(imgGray1, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "# find all contours based off threshold image\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "rect =[]\n",
    "for c in contours:    \n",
    "    [x,y,w,h] = (cv2.boundingRect(c))\n",
    "    rect.append([x,y,w,h])\n",
    "\n",
    "#sort by width (outer box will have largest width)\n",
    "sortedContours = sorted(rect, key= lambda x:x[2], reverse=True)\n",
    "\n",
    "#define corners\n",
    "outerBox = sortedContours[0]\n",
    "topLeft = outerBox[0:2]\n",
    "topRight = [outerBox[0]+outerBox[2], outerBox[1]]\n",
    "bottomLeft= [outerBox[0], outerBox[1]+outerBox[3]]\n",
    "bottomRight = [outerBox[0]+outerBox[2], outerBox[1]+outerBox[3]]\n",
    "pts = [topLeft, topRight, bottomLeft, bottomRight]\n",
    "cv2.circle(imgResize1, tuple(bottomLeft) ,5, (0,0,255), 1)\n",
    "\n",
    "cv2.imshow(\"rect?\", imgResize1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doesnt work if rectangle isnt perfectly \"square on\" :( - cant use bounding rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try read in \"imperfect\" image and find four points for perspective transform using polygon approximation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = r\"C:\\Users\\Halima Mohmed\\Documents\\OEE_OMR\\configFiles\\blankForms\\warp1.jpg\"\n",
    "\n",
    "img = cv2.imread(imgPath)\n",
    "\n",
    "# apply rotations, resizing etc\n",
    "imgResize = cv2.resize(img, dsize=(int(img.shape[1]*0.2), int(img.shape[0]*0.2)), interpolation= cv2.INTER_AREA)\n",
    "imgGray = cv2.cvtColor(imgResize, cv2.COLOR_BGR2GRAY)\n",
    "imgBilat = cv2.bilateralFilter(imgGray, 11,500,0)\n",
    "imgEdges = cv2.Canny(imgBilat, 20,100 )\n",
    "\n",
    "conts = cv2.findContours(imgEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "areas =[]\n",
    "for c in conts[0]:\n",
    "    areas.append([c, cv2.contourArea(c)])\n",
    "\n",
    "#find top 10 biggest contours by area\n",
    "sortedLengths = sorted(areas, key=lambda x:x[1], reverse=True)\n",
    "topConts = sortedLengths[:10]\n",
    "\n",
    "#find outer rectangle \n",
    "outerBoxCnt = None\n",
    "for c in topConts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c[0], True)\n",
    "    #approximate curve to check if its rectangular\n",
    "    approx = cv2.approxPolyDP(c[0], 0.015 * peri, True)\n",
    "    if len(approx) == 4:\n",
    "        outerBoxCnt = approx\n",
    "        break\n",
    "\n",
    "pts = outerBoxCnt.reshape(4,2)\n",
    "\n",
    "#ordered from 0-3: top left, top right, bottom right, bottom left (go clockwise around rect)\n",
    "orderedPts = np.zeros((4,2), dtype='float32')\n",
    "\n",
    "#largest sum of x+y = bottom right\n",
    "#smallest sum of x+y = top left\n",
    "orderedPts[0] = pts[np.argmin(pts.sum(axis=1))]\n",
    "orderedPts[2] = pts[np.argmax(pts.sum(axis=1))]\n",
    "\n",
    "#smallest difference x-y = top right\n",
    "orderedPts[1] = pts[np.argmin(np.diff(pts, axis=1))]\n",
    "#largest difference x-y = bottom left\n",
    "orderedPts[3] = pts[np.argmax(np.diff(pts, axis=1))]\n",
    "\n",
    "#taken from template img\n",
    "tempPts = np.array([[ 20.,  41.],\n",
    "       [858.,  41.],\n",
    "       [858., 637.],\n",
    "       [ 20., 637.]], dtype='float32')\n",
    "\n",
    "#compute matrix to transform from warped img points to template\n",
    "matrix = cv2.getPerspectiveTransform(orderedPts, tempPts)\n",
    "\n",
    "#transform image\n",
    "straightImg = cv2.warpPerspective(imgResize, matrix, (875, 650))\n",
    "\n",
    "cv2.imshow(\"pls\", straightImg)\n",
    "cv2.drawContours(imgResize, [outerBoxCnt], -1, (0,0,255))\n",
    "cv2.imshow(\"bilat\", imgResize)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#unpack ordered pts to find widths and heights\n",
    "(tl, tr, br, bl) = orderedPts\n",
    "\n",
    "#use euclidean distances (finally a use for pythagoras lol) - taken from pyimagesearch.com\n",
    "widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\n",
    "#find max heights/widths - i.e from top/bottom, left/right\n",
    "maxWidth = max(int(widthA), int(widthB))\n",
    "maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "#initialise dst array for transformation\n",
    "dst = np.array([\n",
    "    [0, 0],\n",
    "    [maxWidth-1, 0],\n",
    "    [maxWidth -1, maxHeight-1 ],\n",
    "    [0, maxHeight-1]], dtype = \"float32\")\n",
    "\n",
    "#transformation matrix\n",
    "matrix = cv2.getPerspectiveTransform(orderedPts, dst)\n",
    "\n",
    "#transform image and resize to original size (map spots to correct locations)\n",
    "straightImg = cv2.warpPerspective(imgResize, matrix, (maxWidth, maxHeight))\n",
    "straightImg = cv2.resize(straightImg, (586,439), fx=0.5, fy=0.5)\n",
    "\n",
    "cv2.imshow(\"resize\", straightImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "cv2.imwrite(\"warped1.jpg\", straightImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## play about with masks and omr \"filled\" detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = r\"C:\\Users\\Halima Mohmed\\Documents\\OEE_OMR\\configFiles\\blankForms\\v3.4_blank0.jpg\"\n",
    "img = cv2.resize(cv2.imread(imgPath), (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, imgThresh = cv2.threshold(imgGray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "imgBlank = np.full_like(img, 255)\n",
    "\n",
    "conts = cv2.findContours(imgThresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "omrSpots = []\n",
    "\n",
    "for c in conts[0]: \n",
    "    # compute enclosing circle to get center points\n",
    "    (c_x, c_y), radius = cv2.minEnclosingCircle(c)\n",
    "    c_x = np.round(c_x).astype('float32')\n",
    "    c_y = np.round(c_y).astype('float32')\n",
    "    #draw on blank to show correct detection\n",
    "    cv2.circle(imgBlank, (c_x, c_y), 1, (255,0,0), 5)\n",
    "    omrSpots.append([c_x, c_y])\n",
    "    \n",
    "cv2.imshow(\"blank\", imgBlank)\n",
    "\n",
    "cv2.imshow(\"thresh\", imgThresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort spots by x values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedSpots = sorted(omrSpots, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lots of duplicate spots :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1416"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sortedSpots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate spots\n",
    "remDups =[]\n",
    "for coord in sortedSpots:\n",
    "    if coord not in remDups:\n",
    "        remDups.append(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "820"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remDups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "xCoords = [xy[0] for xy in remDups]\n",
    "yCoords = [xy[1] for xy in remDups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueX = []\n",
    "for x in xCoords:\n",
    "    if x not in uniqueX:\n",
    "        uniqueX.append(x)\n",
    "        \n",
    "uniqueY = []\n",
    "for y in yCoords:\n",
    "    if y not in uniqueY:\n",
    "        uniqueY.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLine = [700]*len(xIndices[0])\n",
    "xLine = [900]*len(yIndices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find points where gap is greater than 5 (removes duplicate points)\n",
    "xIndices = np.where(np.diff(np.array(sorted(uniqueX)))>5)\n",
    "yIndices = np.where(np.diff(np.array(sorted(uniqueY)))>5)\n",
    "\n",
    "#add in last index (wont show up in diff calculation above)\n",
    "xIndices = np.append(xIndices[0], -1)\n",
    "yIndices = np.append(yIndices[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualise unique x and y coordinates detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = list(zip(list(np.array(sorted(uniqueX))[xIndices ]), yLine))\n",
    "\n",
    "yTest = list(zip(xLine, list(np.array(sorted(uniqueY))[yIndices])))\n",
    "\n",
    "img = cv2.resize(cv2.imread(imgPath), (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "for pt in xTest:\n",
    "    #print(xy)\n",
    "    cv2.circle(img, pt, 2, (0,0,255))\n",
    "    \n",
    "for pt in yTest:\n",
    "    #print(xy)\n",
    "    cv2.circle(img, pt, 2, (0,0,255))\n",
    "    \n",
    "cv2.imshow(\"blank\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get around issue by providing different template image? i.e fill in spots to improve contour detection, (inner and outer circles detected as separate contours with \"empty spots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = r\"C:\\Users\\Halima Mohmed\\Documents\\OEE_OMR\\configFiles\\blankForms\\v3.4_blank_filled0.jpg\"\n",
    "img = cv2.resize(cv2.imread(imgPath), (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, imgThresh = cv2.threshold(imgGray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "imgBlank = np.full_like(img, 255)\n",
    "\n",
    "conts = cv2.findContours(imgThresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "omrSpots = []\n",
    "\n",
    "for c in conts[0]: \n",
    "    # compute enclosing circle to get center points\n",
    "    (c_x, c_y), radius = cv2.minEnclosingCircle(c)\n",
    "    c_x = np.round(c_x).astype('float32')\n",
    "    c_y = np.round(c_y).astype('float32')\n",
    "    #draw on blank to show correct detection\n",
    "    cv2.circle(imgBlank, (c_x, c_y), 1, (255,0,0), 5)\n",
    "    omrSpots.append([c_x, c_y])\n",
    "    \n",
    "cv2.imshow(\"blank\", imgBlank)\n",
    "\n",
    "cv2.imshow(\"thresh\", imgThresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort by x, then y\n",
    "sortedSpots = sorted(omrSpots, key=lambda x:(x[0], x[1]))\n",
    "len(sortedSpots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(cv2.imread(imgPath), (0,0), fx=0.5, fy=0.5)\n",
    "\n",
    "for spot in sortedSpots[650:]:\n",
    "    cv2.circle(img, tuple(spot), 5, (0,0,255), thickness=-1)\n",
    "    \n",
    "cv2.imshow(\"spots\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to deal with x,y coords that are not exactly the same, but v close?\n",
    "\n",
    "## 1. find unique x and y, and then remove duplicates based off small np.diff vals?\n",
    "## 2. (re)zip newly defined unique x and y coords\n",
    "## 3. define new omr spots \"matrix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1021.0, 452.0],\n",
       " [1021.0, 483.0],\n",
       " [1021.0, 530.0],\n",
       " [1021.0, 546.0],\n",
       " [1021.0, 624.0],\n",
       " [1021.0, 640.0],\n",
       " [1021.0, 671.0],\n",
       " [1021.0, 687.0],\n",
       " [1021.0, 718.0],\n",
       " [1021.0, 734.0],\n",
       " [1022.0, 216.0],\n",
       " [1022.0, 232.0],\n",
       " [1022.0, 248.0],\n",
       " [1022.0, 263.0],\n",
       " [1022.0, 279.0],\n",
       " [1022.0, 295.0],\n",
       " [1022.0, 310.0],\n",
       " [1022.0, 326.0],\n",
       " [1022.0, 342.0],\n",
       " [1022.0, 358.0],\n",
       " [1022.0, 420.0],\n",
       " [1022.0, 467.0],\n",
       " [1022.0, 498.0],\n",
       " [1022.0, 514.0],\n",
       " [1022.0, 593.0],\n",
       " [1022.0, 608.0],\n",
       " [1022.0, 655.0],\n",
       " [1022.0, 702.0]]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedSpots[680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
